{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro"
    ]
   },
   "source": [
    "# Grading process\n",
    "\n",
    "\n",
    "The submission notebook will be autovalidated with `papermill`. The exact command is the following:\n",
    "\n",
    "```bash\n",
    "papermill <notebook-name>.ipynb <notebook-name>-run.ipynb .ipynb -p TEST True\n",
    "```\n",
    "\n",
    "Papermill will inject new cell after each cell tagged as `parameters` (see `View > Cell toolbar > Tags`). Notebook will be executed from top to bottom in a linear order. `solutions.py` contains correct implementations used to validate your solutions.\n",
    "\n",
    "Please, **fill `STUDENT` variable with the name of submitting student**, so that we can collect the results automatically. Please, **do not change `TEST` variable** and `validation` cells. If you need to inject your own code for testing, wrap it into\n",
    "\n",
    "```python\n",
    "if not TEST:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Different problems give different number of points. All problems in the basic section give 1 point, while all problems in intermediate section give 2 points.\n",
    "\n",
    "Each problem contains specific validation details. You need to fill each cell tagged `solution` with your code. Note, that solution function must self-contained, i.e. it must not use any state from the notebook itself.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "All problems in the assignment use [electricity load dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). Some functions/methods accept data itself, and in that case it's a Pandas dataframe as obtained by\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "In contrast, whenever a function/method accepts a filename, it's the filename of **unzipped** data file (i.e. `LD2011_2014.txt`). When testing, do not rely on any specific location of the dataset, as validation environment will most certainly different from your local one. Hence, calls like\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"<your-local-directory>/LD2011_2014.txt\")\n",
    "```\n",
    "\n",
    "will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.111972Z",
     "start_time": "2019-10-30T22:26:04.107385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.372936Z",
     "start_time": "2019-10-30T22:26:04.364608Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Omri Kazelnik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ASSIGNMENT = 1\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:38.188583Z",
     "start_time": "2019-10-30T22:39:38.182534Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 1. Resample the dataset (1 point)\n",
    "\n",
    "Resample the dataset to 1-hour resolution. Use `mean` as an aggregation function. Your function must output a dataframe, with the same structure as the original one (i.e. not indexed by datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.100307Z",
     "start_time": "2019-10-30T22:26:07.092132Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def el_resample(df):\n",
    "    resampled_df = df.resample('1H', on='timestamp').mean()\n",
    "    resampled_df['timestamp'] = resampled_df.index\n",
    "    resampled_df.reset_index(drop=True, inplace=True)\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.334174Z",
     "start_time": "2019-10-30T22:26:07.322103Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, el_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 2. Consumption peaks (1 point)\n",
    "\n",
    "For each household, calculate, which month in 2014 had the highest consumption. Your function must output series, indexed by household ID (e.g., `MT_XXX`), and containing month as an integer (`1-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.274476Z",
     "start_time": "2019-10-30T22:26:08.268426Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def cons_peak(df):\n",
    "    peak_df = df.copy()\n",
    "    peak_df['timestamp'] = pd.to_datetime(peak_df['timestamp'])\n",
    "    peak_df = peak_df[peak_df['timestamp'].dt.year == 2014]\n",
    "    peak_df = peak_df.resample('1M', on='timestamp').mean()\n",
    "    return peak_df.idxmax().dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.554208Z",
     "start_time": "2019-10-30T22:26:08.542546Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, cons_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 3. Find minimum (2 points)\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given $a,b,c$, find $x$, which minimizes $f(x)$, and minimum value of $f(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor.\n",
    "\n",
    "For reference, see `generate_coef` function, which is used to generate coefficients. Note, that since optimization process is not completely deterministic, the output is considered correct, if it falls within `1e-3` of actual values.\n",
    "\n",
    "This problem must be solved as an optimization one using gradient descent.\n",
    "\n",
    "For that, use only PyTorch functionality, `SciPy` (or alike) optimization routines are not allowed, neither is direct calculation using coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.950073Z",
     "start_time": "2019-10-30T22:26:08.944541Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def find_min(a, b, c):\n",
    "    dtype = torch.float\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    x = torch.randint(-1, 1, (1,), dtype=dtype, device=device, requires_grad=True)\n",
    "    alpha = 1e-2\n",
    "    stop_precision = 1e-7\n",
    "\n",
    "    while x.grad is None:\n",
    "        y = func(x=x, a=a, b=b, c=c)\n",
    "        y.backward()\n",
    "        update = x.data - alpha * x.grad.data\n",
    "        if torch.abs(x - update) > stop_precision:\n",
    "            x.grad = None\n",
    "        x.data = update\n",
    "\n",
    "    return x.data[0], func(x=x.data, a=a, b=b, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.170219Z",
     "start_time": "2019-10-30T22:26:09.158251Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 4. PyTorch `Dataset` (3 points)\n",
    "\n",
    "Implement a `torch.utils.data.Dataset` sub-class for the electricity consumption data. Individual training instances must be week-long univarite series of hourly consumption (input, 168 values), followed by 24-hours long series of hourly consumption (output, 24 values) for a single household. Such a class can be used when training a consumption forecast model, which uses 7 days of historical consumption to forecast next 24 hours of consumption.\n",
    "\n",
    "`__getitem__(self, idx)` must return a tuple of 1D tensors, `in_data` and `out_data`. `in_data` contains 168 hours of consumption (hourly), starting from some `start_ts`, while `out_data` must contain 24 hourly consumption values starting from `start_ts + 168 hours` for some household. `start_ts` should be sampled randomly.\n",
    "\n",
    "Also, you need to implement a `get_mapping(self, idx)` method, which allows to calculate `(household, starting time) -> idx` correspondence.\n",
    "\n",
    "This class will be validated as the following:\n",
    "\n",
    "- dataset object is created with some random `samples`: `dataset = ElDataset(df, samples)` ,\n",
    "- validator fetches random `idx` (between `0` and `len(dataset)`) from the dataset:\n",
    "```python\n",
    "household, start_ts = dataset.get_mapping(idx)\n",
    "hist_data, future_data = dataset[idx]\n",
    "```\n",
    "- then, `hist_data` and `future_data` are compared with the data, obtained directly from `df` using `household, start_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.531869Z",
     "start_time": "2019-10-30T22:26:09.523705Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class ElDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Electricity dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: original electricity data (see HW intro for details).\n",
    "            samples (int): number of sample to take per household.\n",
    "        \"\"\"\n",
    "        self.raw_data = df.set_index(\"timestamp\")\n",
    "        self.raw_data = self.raw_data.resample('1H').mean()\n",
    "        self.samples = samples\n",
    "        self.min_date = None\n",
    "        self.max_date = None\n",
    "        self.mappings = None\n",
    "\n",
    "        # setters\n",
    "        self.set_min_max_dates()\n",
    "        self.set_mappings()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_household_from_id(household_id):\n",
    "        if 0 <= household_id < 10:\n",
    "            return f\"MT_00{household_id}\"\n",
    "        elif 10 <= household_id <= 99:\n",
    "            return f\"MT_0{household_id}\"\n",
    "        else:\n",
    "            return f\"MT_{household_id}\"\n",
    "\n",
    "    def set_min_max_dates(self):\n",
    "        self.min_date = min(self.raw_data.index).date()\n",
    "        self.max_date = max(self.raw_data.index).date() - timedelta(days=8)\n",
    "\n",
    "    def set_mappings(self):\n",
    "        dates_pool = pd.date_range(start=self.min_date, end=self.max_date, freq='1H').tolist()\n",
    "        self.mappings = {\n",
    "            idx: pd.to_datetime(random.choice(dates_pool))\n",
    "            for idx in range(self.__len__())\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples * self.raw_data.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        household, start_training_ts = self.get_mapping(idx=idx)\n",
    "        end_training_ts = pd.to_datetime(start_training_ts + timedelta(hours=167))  # takes 7 days for train\n",
    "        start_test_ts = pd.to_datetime(end_training_ts + timedelta(hours=1))\n",
    "        end_test_ts = pd.to_datetime(start_test_ts + timedelta(hours=23))  # takes 24 hours for test\n",
    "\n",
    "        return torch.tensor(self.raw_data.loc[start_training_ts:end_training_ts][household].values), \\\n",
    "           torch.tensor(self.raw_data.loc[start_test_ts:end_test_ts][household].values)\n",
    "\n",
    "    def get_mapping(self, idx):\n",
    "        household_id = (idx // self.samples) + 1\n",
    "        return ElDataset.create_household_from_id(household_id), self.mappings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.716713Z",
     "start_time": "2019-10-30T22:26:09.707934Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, ElDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:26.661611Z",
     "start_time": "2019-10-30T22:39:26.654545Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {total_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
